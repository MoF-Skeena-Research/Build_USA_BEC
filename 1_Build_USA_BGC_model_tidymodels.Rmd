---
title: "Model USA Biogeoclimatic Units using Machine Learning"
author: "William H MacKenzie and Kiri Daust"
date: "17/10/2019"
output: 
   html_document:
  code_folding: hide
  #theme: flatly
---
### Script to create RF model from USA training points and predict + map US zones/ subzones (predicted within each zone)
1. Import training data
2. Reduce variable list with caret or PCA all variable
3. Test machine learning model with analysis/assessment splits and CV
4. Report errors rate
5. Build final model
6. Predict 
Translates predictions to a grid point map
Add predictions to hex polygon layer.
Overlay additional plots over map to assign to USA_BGC units


# STEP 1: Prepare dataset for analysis----clear workspace
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
require(reshape)
require(reshape2)
require(parallel)
require(foreach)
require(doParallel)
require(ggplot2)
require(dplyr)
require(ranger)
require (tools)
require(data.table)
require(spatstat)
#require(spatialEco)
require(survey)
require(scales)
require(tidyverse)
require(rlang)
require(Rcpp)
require(forcats)
require(purrrlyr)
require(skimr)
require(smotefamily)
require(tictoc)
require(tidymodels)
require(spatialsample)
require(themis)
# require(conflicted)
require(ggtext)
tidymodels_prefer()
#install.packages ("spThin")
conflicted::conflict_prefer(name = "spec", winner = "yardstick")

source("./_functions/AddVars.R")
source("./_functions/removeOutlier.R")
source("./_functions/acc_metrix.R")
```

# Import USA training point data 
CSV file with all variable climate data generated by ClimateNA for the 1960-91 Normal Period.
*** Need to update data to climateNA7

Several additional climate variables are calculated
```{r input data, echo=FALSE}
###read in training point data - update BGC with revise classification if required
X1 <- fread("./inputs/training_pts/USA_training_13Nov2023_1961_90.csv",  stringsAsFactors = FALSE,data.table = FALSE) %>% filter(!BGC == "NA")


## update BGC from new table with updated BGC if assigned
#X1 <- X1 %>% dplyr::select(-BGC)
#X1_new <- fread("./inputs/training_pts/US_TrainingPoints_27Dec2020.csv",  stringsAsFactors = FALSE,data.table = FALSE)
#X1_new <- X1_new %>% dplyr::select(ID1, BGC)
#X1 <- left_join(X1, X1_new, by = "ID1") %>% filter(!BGC == "NA")

##temporary updates
# X1_new2 <- fread("./inputs/training_pts/CWHvm_to_CWHms_2.csv",  stringsAsFactors = FALSE,data.table = FALSE)
# X1_new2$BGC <- recode(X1_new2$BGC, "CWHvm_WA" = "CWHms_WA") 
# X1_new2 <- X1_new2 %>% dplyr::select(ID1, BGC) 
# X1_new <- left_join(X1_new, X1_new2, by = "ID1")
# X1_new$BGC.y <- ifelse(is.na(X1_new$BGC.y), X1_new$BGC.x, X1_new$BGC.y)
# X1_new <- X1_new %>% select(ID1, BGC.y) %>% rename(BGC = BGC.y)
## update BGC from new table with updated BGC



##Add in border points from BC and Alberta from WNA 4k Grid data
#Y1 <- fread("./inputs/training_pts/Border_TrainingPoints_2Sept2021_Normal_1961_1990MSY.csv",  stringsAsFactors = FALSE,data.table = FALSE) %>% as_tibble


#Y2 <- Y1  %>% filter(Latitude < 49.5) #%>% filter(BGC %in% c("CDFmm", "ICHdm", "IDFxx1", "CWHms1", "MSdm2"))
# Y3 <- Y1 %>% filter(Latitude > 49.001) %>% filter(Latitude < 49.2)
# Y3.count <- Y3 %>% count(BGC) %>% filter(n>30)
# Y3 <- Y3[Y3$BGC %in% Y3.count$BGC,]
#   dplyr::select(1:5)
# fwrite(Y3,"./inputs/training_pts/Border_TrainingPoints_2Sept2021.csv" )#X1 <- rbind(X1,Y2) %>% select(-ID1) %>%  rowid_to_column("ID1")
X <- rbind(X1,Y1)

# X1_loc <- X1 %>% dplyr::select(ID1, Latitude, Longitude, Elevation)
# X1 <- X1 %>% dplyr::select (ID1, BGC, everything()) %>% dplyr::select(-Latitude, -Longitude, -Elevation)

# X2 <- fread("./cLHS/WNA_Training_22_VARS.csv", stringsAsFactors = FALSE, data.table = FALSE)
# X3 <- left_join(X2, X1) %>% dplyr::select(ID1, BGC, Latitude, Longitude, Elevation)
# write.csv(X3, "LHS_Training_Locations.csv")


X2 <- addVars(X)
#X1 <- X1 %>% dplyr::select(ID1, BGC, everything())
### 33 Bioclimate variable set from DataBasin version 7
X1 <- X2 %>% dplyr::select(ID1, Latitude, Longitude, BGC,  MWMT, MCMT, MSP, AHM, SHM,  DD5,  DD18, NFFD, bFFP, eFFP, 
        PAS, EMT, EXT, Eref, CMDMax, CMD.total,  Tave_wt, Tave_sm,  PPT_sm,
        FFP, MAT, TD, MAP, DD_18, DD_0, PPT_wt) 

#X3 <- X2 %>% dplyr::select(ID1, BGC, Latitude, Longitude, MAT, MWMT, MCMT, TD, MAP, MSP, AHM, SHM, DD_0, DD5, DD_18, DD18, 
#                           NFFD, FFP, bFFP, eFFP, PAS ,EMT, EXT, Eref, CMD, MAR, RH, CMI, DD1040, 
#                           Tave_wt, Tave_sp, Tave_sm, Tave_at, PPT_wt, PPT_sp, PPT_sm, PPT_at,
#                           CMDMax, CMD.total)
# this set could be poorMAR, RH,
# X1 <- X1 %>% dplyr::select(ID1, BGC, MWMT, DD5_at, DD5_sm, DD5_sp, Eref_sm, Eref_sp, PPT_sm, MSP, PPT_sp,
#          CMD_sp, CMDMax,CMD.total,SHM, AHM, Tmax_sp, Tmax_sm, DD18, NFFD)
#$BGC <- as.factor(X1$BGC)

```


# remove undersampled BGCs
```{r remove undersampled}
##count of BGC points
num_pts <- X1 %>% group_by(BGC) %>% count()
bad_BGCs <- num_pts %>% filter(n<50) %>% select(BGC)
fwrite(num_pts, "./outputs/TrainingPointCount.csv")

removeBGCs <- c("duplicate", "Duplicate", "na")
X1 <- X1 %>% filter(!(BGC %in% bad_BGCs))# %>% filter(Latitude >= 41)


# merge parkland into adjacent alpine unit
X1$BGC <- X1$BGC %>% recode( MHdsp_OR = "CMAun_OR", MHRFdmp_OR = "CMAun_OR", MHRFmmp_OR = "CMAun_OR", MHmsp_WA = "CMAun_WA",
                             "MHRFdsp_CA" = "CMAun_CA", "MHdsp_OR" = "CMAun_OR" , "MHRFdmp_OR"= "CMAun_OR" , "MHRFmmp_OR"= "CMAun_OR" , 
                            "MHmsp_WA" ="CMAun_WA" , "MHmmp_WA"= "CMAun_WA" ,"MHdmp_OR"= "CMAun_OR",
                             "ESSFxcp_CO"=  "IMAun_CO" , "ESSFwmp_MT"="IMAun_MT" , "ESSFxkp_UT"= "IMAun_UT" , "ESSFxkp_MT"= "IMAun_MT" , 
                             "ESSFdmp_ID"="IMAun_ID" ,"ESSFdkp_MT"=  "IMAun_MT" ,"ESSFxcp_WA" = "IMAun_WA" ,"ESSFmwp_WA" = "IMAun_WA" ,
                           "ESSFxwp_OR" = "IMAun_OR", "ESSFxxp_WY" = "IMAun_WY", "ESSFxkp_WY" = "IMAun_WY" )

### count training points per BGC
count_tp <- X1 %>% dplyr::count(BGC) %>% filter(n<=10) %>% select(BGC)
count_tp <-  as.character(count_tp$BGC)
X1 <- X1 %>% filter(!BGC %in% count_tp)

## merge of related units with high confusion in first run
#X1$BGC <- X1$BGC %>% recode( CDFmm_WA = "CDFmm")# , MHRFdmp_OR = "CMAun_OR")
#                             , MHRFmmp_OR = "CMAun_OR", MHmsp_WA = "CMAun_WA",
#                              "MHRFdsp_CA" = "CMAun_CA", "MHdsp_OR" = "CMAun_OR" , "MHRFdmp_OR"= "CMAun_OR" , "MHRFmmp_OR"= "CMAun_OR" , 
#                             "MHmsp_WA" ="CMAun_WA" , "MHmmp_WA"= "CMAun_WA" ,
#                              "ESSFxcp_CO"=  "IMAun_CO" , "ESSFwmp_MT"="IMAun_MT" , "ESSFxkp_UT"= "IMAun_UT" , "ESSFxkp_MT"= "IMAun_MT" , 
#                              "ESSFdmp_ID"="IMAun_ID" ,"ESSFdkp_MT"=  "IMAun_MT" ,"ESSFxcp_WA" = "IMAun_WA" ,"ESSFmwp_WA" = "IMAun_WA" ,
#                            "ESSFxwp_OR" = "IMAun_OR" )
X1 <- X1 %>% mutate(across(where(is.numeric), ~na_if(.,-9999.0))) %>% drop_na()

 count_tp <- X1 %>% dplyr::count(BGC)

 BGCs <- sort(unique(X1$BGC))
BGCs
#X1 <- X2
```
The preprocessing function from the caret package was used to identify variables with near-zero variance or correlation >0.90 in the combined data set. These variables were removed leaving a final variable set of 20 variables.
```{r reduce variables, warning=FALSE} 
########Remove near zero variance and highly correlated variables
# X1_no_nzv_pca <- preProcess(X2a[,-c(1:3)], method = c( "nzv")) # DROP variables with near zero variance
#  X1_no_nzv_pca
#  X2b <- dplyr::select(X2a, -c(X1_no_nzv_pca$method$remove))
#  X1 <- X1 %>%  na_if(-9999.0) %>% drop_na()
# 
# # calculate correlation matrix of variables
 # correlationMatrix <- cor(X2a[,-c(1:4)])
# # summarize the correlation matrix
# #print(correlationMatrix)
# # find attributes that are highly corrected (ideally >0.75)
 # highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.95, verbose = TRUE, names = TRUE) ## review for removal of highly correlated vars
 # X2b <- X2a %>% dplyr::select(-c(highlyCorrelated))%>% drop_na(BGC)
# 
# 
# modelvars <- colnames(X1 %>% dplyr::select(-ID1,  -BGC, everything()))
# X1 <- X1 %>% dplyr::select(ID1, BGC, all_of(modelvars))
# 
# # modelvars <- read.csv("./inputs/Final14Var_WNABGCv11.csv")##use model variables from buildrf work
# #X1 <- X1 %>% dplyr::select(ID1, BGC, modelvars$x) %>% drop_na(BGC)
# X1$BGC <- as.factor(X1$BGC)
# X1 <- droplevels(X1)

```


##Remove outliers points
Looks for training points which fall climatically well outside of the normal range by BGC.
Mostly aimed at catching the 10% of FIA plots which have been given an intentionally large offset georeferenced location
May also indicate overly broad BGCs (eg. IMAus)

```{r remove outlier points}

# outs <- function(dat) {
# Q <- quantile(dat$vals, probs = c(.25, .75), na.rm = TRUE)
# iqr <- IQR(dat$vals)
# up <-  Q[2] + 1.5 * iqr # Upper Range
# low <- Q[1] - 1.5 * iqr # Lower Range
# dat$vals <- ifelse(dat$vals > up, NA,
# ifelse(dat$vals < low, NA, dat$vals))
# dat
# }
# XAll <- X1 %>% distinct()
# outlier.var <- c("DD5", "CMD.total", 'PPT_JAS', 'MCMT')
# XAll3 <- pivot_longer (XAll,!c(BGC, ID1), names_to = "vars", values_to = "vals") %>% unite(BGCvar, c("BGC", "vars"), remove = FALSE) %>% distinct()
# XAll3.1 <- XAll3 %>% filter(!vars %in% outlier.var)%>% distinct()
# XAll3.2 <- XAll3 %>% filter(vars %in% outlier.var)%>% distinct()
# Xreduce <- as.data.frame(XAll3.2)  %>% group_by(BGCvar) %>%  do(outs(.))
# Xreduce <- as.data.frame(Xreduce)  %>% select (ID1, BGC, vars, vals)
# IDs <- XAll3 %>% select(ID1, BGC) %>% distinct(ID1, .keep_all = TRUE)
# #XAll3$BGCvar <- as.factor(XAll3$BGCvar)
# XAll4 <- pivot_wider(Xreduce, id_cols = c(ID1,BGC), names_from = vars, values_from = vals)#, values_fn = length) #%>% distinct()
# XAll5 <- left_join(IDs, XAll4) %>% na_if(NA)
# X2 <- XAll5 %>% na.omit()   %>% select(ID1) %>% left_join(XAll)%>% mutate_if(is.character, as.factor) %>% mutate_if(is.integer, as.numeric)
# X2$ID1 <- as.integer(X2$ID1)# %>% dplyr::select(BGC, AHM, CMD.total, MWMT)
# count_tp <- X2 %>% dplyr::count(BGC)


# X1_Bio1 <- X1_Bio1  %>% select( -BGC) %>% select (Zone, everything())
# # require(psych)
# # require(outliers)
# # X1_test <- X1_Bio1[X1_Bio1$Zone == "CMA",]
# # X1_test <- X1_test[,-c(4:17)]
#  outlier <- psych::outlier(X1_Bio1[-1])
#  X1_Bio1 [,-c(1)] <- dmap (X1_Bio1 [,-c(1)], as.numeric)

#  
# 


 X2 <- removeOutlier(X1, alpha = .025, numIDvars = 4) ###set alpha for removal of outlieres (2.5% = 3SD)
 count_tp <- X2 %>% dplyr::count(BGC)
 
 ####show histogram of variables
 #skimmed <- skim(X2)
#skimmed


# 
# featurePlot(x =  X1[, -c(1:2)],
#             y =  X2$Zone,
#             plot = "box",
#             strip=strip.custom(par.strip.text=list(cex=.7)),
#             scales = list(x = list(relation="free"),
#                           y = list(relation="free")))

```

## Remove points to ensure a spacing of at least 1km between training points

```{r thin data to limit spatial autocorrelation}
## turn X2 into a spatial object and convert to a projected georef (3005?)
rad_exclusion = 1000 ##  minimum meters between points

### code used in PEM cLHS sampling as example      
# clhs_sampled <- st_as_sf(X2) %>%
#         mutate(final_obj_continuous = clhs_slice$final_obj_continuous) %>% 
#         mutate(slice_num = i)
#       
#       for(j in 1:nrow(clhs_sampled)){ # Filter the close together samples from the cLHS run
#        # j = 1
#         if(!is.na(clhs_sampled[j, ])){
#           distances <- data.frame(distance = st_distance(clhs_sampled, clhs_sampled[j, ])) %>%
#             rownames_to_column() %>%
#             mutate_all(as.numeric) %>%
#             dplyr::filter(distance > rad_exclusion | distance == 0)
#           clhs_sampled <- clhs_sampled[distances$rowname, ]
#         }
#       }
#       clhs_sampled_buff <- st_buffer(clhs_sampled, dist = rad_exclusion) # Extract and buffer the cLHS points
#       lays <- mask(lays, clhs_sampled_buff, inverse = TRUE) # Mask the sampleable area
#       
#       sample_points <- bind_rows(sample_points, clhs_sampled ) 

```

### training point distribution bar graphs
```{r raw training point summary, echo = FALSE, include = TRUE}
# calculate summary of raw training data set
X2_sum <- X2 %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot(X2_sum, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))

X2$BGC <- as.factor(X2$BGC)

BGC_split <- initial_split(X2, prop = 3/4, strata = BGC)
BGC_train <- training(BGC_split)
BGC_test <- testing(BGC_split)

```

```{r tidy parameters, include = TRUE, echo = TRUE}

BGC_recipe <-
    recipe(BGC ~ ., data = BGC_train) %>%
    update_role(ID, new_role = "id variable") %>% 
    update_role(lat, long, new_role = "georef") %>% 
    #step_corr(all_numeric(0.9)) %>%        # remove correlated covariates
    #step_dummy(all_nominal(),-all_outcomes()) %>%   
    #step_zv(all_numeric()) %>%          # remove values with no variance
    prep()
  summary(BGC_recipe)
  
# pre-processed training point data check 

#table(training_dat$target)
  BGC_train_sum <- BGC_train %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_train_sum, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
    ggtitle("Training Set")
    
## note in RF as a tree based model it is not required to scale and normalize covariates and may have negative influence on the model performance 

BGCbalance_recipe <-  recipe(BGC ~ ., data =  BGC_train) %>%
    update_role(ID, new_role = "id variable") %>% 
    update_role(lat, long, new_role = "georef") %>% 
    #step_corr(all_numeric()) %>%        # remove correlated covariates
    #step_dummy(all_nominal(),-all_outcomes()) %>%    
    # step_zv(all_numeric()) %>% # remove values with no variance
  step_downsample(BGC, under_ratio = 70) %>%   
  step_smote(BGC, over_ratio = .2, neighbors = 10) %>% 
    prep()
BGC_train2 <- BGCbalance_recipe  %>% juice()
BGC_train2$BGC <- as.factor(BGC_train2$BGC)
  
  BGC_train_sum2 <- BGC_train2 %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_train_sum2, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Up/downsampled set")
 count_tp2 <- BGC_train2 %>% dplyr::count(BGC)

```



```{r fit non-cv model fpr comparison, error=TRUE}
randf_spec <- rand_forest(mtry = 6, min_n = 2, trees = 101) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = 'permutation') #or "permutations"impurity"

BGC_workflow <- workflow() %>%
    add_recipe(BGCbalance_recipe) %>%
    add_model(randf_spec)

BGC_rf1 <- fit(
  BGC_workflow, 
  BGC_train)


```

```{r predict test set}

######### Predict Test
test_target <- as.data.frame(BGC_test$BGC) %>% rename(BGC = 1)
test.pred <-  predict(BGC_rf1, BGC_test)
test.pred <- cbind(test_target, test.pred) %>% mutate_if(is.character, as.factor)
# levels(train.pred$target)

###harmonize levels
targ.lev <- levels(test.pred$BGC); pred.lev <- levels(test.pred$.pred_class)
levs <- c(targ.lev, pred.lev) %>% unique()
test.pred$BGC <- factor(test.pred$BGC, levels = levs)
test.pred$.pred_class <- factor(test.pred$.pred_class, levels = levs)
# 
# 
# train.acc <- acc_metrix(train.pred) %>% rename(train = .estimate)
source("./_functions/acc_metrix.R")
test.acc <- acc_metrix(test.pred) %>% dplyr::select(.metric, .estimate) %>% rename(metric = 1, test = 2)

test.out <-   test.pred %>% 
   conf_mat(BGC, .pred_class) %>%
   pluck(1) %>%
   as_tibble()# %>%
   

# ggplot(test.out, aes(Prediction, Truth, alpha = n)) +
#    geom_tile(show.legend = FALSE) +
#    geom_text(aes(label = n), colour = "black", alpha = 1, size = 3) + 
#    theme(axis.text.x = element_text(angle = 90)) 
## compare cv stats to test stats  
  #acc.compare <- cbind(final_metrics, test.acc)

 # kable(acc.compare)
```

```{r create deviation graphic}
# calculate predicted vs obs pc for balancing types 
# negative number = under predict and positive = over predicted)

BGC.truth <- test.pred %>%
  count(BGC) %>% rename("truth" = n)
BGC.pred <- test.pred %>%
  count(.pred_class) %>% rename("predict" = n, "BGC" = .pred_class)
BGC_dev <- left_join(BGC.truth, BGC.pred) %>% group_by(BGC)
BGC_dev <- BGC_dev %>% 

  mutate(pred.diff = predict - truth,
         pred_pc = (pred.diff/truth) * 100) %>% arrange(pred_pc)

df_total <- as.data.frame(BGC_dev) %>% replace(is.na(.), 0)

df_total2 <- df_total  %>%  group_by() %>% 
            summarise(dev_tot = sum(abs(pred_pc)),
            dev_var = var(abs(pred_pc)),
            dev_mean = mean(abs(pred_pc)),
            dev_sd = sd(abs(pred_pc))) 


devtext <- as.data.frame(t(df_total2)) %>% round(1) %>% rownames_to_column()


BGC_dev  <- BGC_dev  %>%
  mutate(BGC = fct_reorder(BGC, pred_pc))

  ds_plot <- BGC_dev %>%   ggplot( aes(x=reorder(BGC, pred_pc), y=pred_pc)) +
    geom_bar(stat='identity', width=.5) + #aes(fill = pred.obs.type)
    coord_flip(ylim =c(-100, 110))
label = df_total2 [3] %>% round(1)
ds_plot <- ds_plot +
  geom_textbox(data = devtext, width = .1,
            size = 3, 
            mapping = aes(x = 20 , y = -60 ,label = label),
            colour = "blue"
  )

ds_plot
require(ggpubr)
ggexport(ds_plot, filename  = "./outputs/Deviation_graph.jpg", pointsize = 6, width = 800, height = 1200)

```
```{r build final tidy model}
require(themis)
BGC_final <- X2 %>% select(-Latitude, -Longitude)


randf_spec <- rand_forest(mtry = 6, min_n = 2, trees = 201) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "permutation") #or "permutations


BGC_recipe <-  recipe(BGC ~ ., data =  BGC_final) %>%
    update_role(ID1, new_role = "id variable") %>% 
  step_downsample(BGC, under_ratio = 70) %>%   
  step_smote(BGC, over_ratio = .1, neighbors = 5) %>%
 prep()


BGC_workflow <- workflow() %>%
    add_recipe(BGC_recipe) %>%
    add_model(randf_spec)
### Show number of final training points
BGC_all <- BGC_recipe  %>% juice()
BGC_all$BGC <- as.factor(BGC_all$BGC)
  BGC_all <- BGC_all %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_all, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Up/downsampled set")



BGCmodel <- fit(
  BGC_workflow, 
  BGC_final)

save(BGCmodel,file= "./outputs/USAv12_w_BCborder_5Apr2022tidymodel.Rdata")
#load("./outputs/USAv12_tidymodel.Rdata")

##report model
  require(vip)
final_fit <- extract_fit_parsnip(BGCmodel) # %>%pull(.predictions)
final_fit
oob  <- round(BGCmodel$fit$fit$fit$prediction.error, 3)
extract_fit_parsnip(BGCmodel) %>% vip(num_features = 26)

```

# Build Subzone models and predict within each Zone
####now build models for each subzone and then predict gridpoints by subzone model
Advice of Tom Hengel is that single model is more mathematically justified

``` {r Build Subzone model and predict}

# # Grid data from previous chunk
# pointDat <- grid.dat
# pointDat <-  pointDat %>% select(Zone, everything()) %>% arrange(Zone)
# 
# ######################################################
# #Training point data from above
# X2 <-  X1.info %>% select(Zone, everything()) %>% arrange(Zone)
# X2$BGC <-  as.factor(X2$BGC)
# Zones <- as.character(unique(X2$Zone))
# Zones <- sort (Zones)
# X2 <- droplevels(X2)
# # X2 <- X2[X2$Zone == "CMA",]
# # Zones <- as.character(unique(X2$Zone))
# # Zones <- sort (Zones)
# SZPred <- foreach(Z = Zones, .combine = rbind) %do% {
#   trainSub <- X2[X2$Zone == Z,]###subset training points to only include selected zone
#    if(length(unique(trainSub$BGC)) >= 2){ ###somtimes there aren't any subzones skip to else
#     trainSub$BGC <- as.factor(trainSub$BGC)
#     trainSub$BGC <- droplevels(trainSub$BGC)
#     trainSub <- removeOutlier(trainSub, alpha = 0.001)
# ###build model for each subzone individually
#     set.seed(123321)
# coreNo <- makePSOCKcluster(detectCores() - 1)
# registerDoParallel(coreNo, cores = detectCores() - 1)
# Cores <- as.numeric(detectCores()-1)
# 
# SZmodel <- train(BGC  ~ ., data = trainSub [-1],
#                      method = "ranger",
#                      trControl = trainControl(method="cv", number = 10, verboseIter = T, classProbs = T, savePredictions = "final"),
#                      #num.trees = 11,
#                      preProcess = c("center", "scale", "YeoJohnson"),#,tuneGrid = tgrid,
#                      importance = "impurity")
# 
#  stopCluster(coreNo)
# gc()
#       # SZmodel <- randomForest(BGC ~ ., data=trainSub [-1], nodesize = 5, do.trace = 10,
#       #                       ntree=101, na.action=na.fail, importance=TRUE, proximity=FALSE)
# 
#    
#     pointSub <- pointDat[pointDat$Zone == Z,] ###subset grid based on previously predicted zones
#     pointSub$BGC<- predict(SZmodel, newdata = pointSub[,-c(1:4),]) ### predict subzones
#     out <- pointSub[,c("ID1", "Latitude","Longitude","Zone", "BGC")]
#     out
#   }else{ ##if only one subzone, plot
#     pointSub <- pointDat[pointDat$Zone == Z,]
#     #pointSub$Zone <- droplevels(pointSub$Zone)
#     pointSub$BGC <- pointSub$Zone
#     out <- pointSub[,c("ID1", "Latitude","Longitude","Zone", "BGC")]
#     out
#   }
#   
# }
# 
# grid.sbz <- dplyr::select(SZPred, ID1, BGC, Zone)#"Longitude","Latitude", "Elevation", "Zone")]
# grid.sbz <- droplevels(grid.sbz)
# table(grid.sbz$BGC)
# grid.dat.pred <- left_join(grid.dat, grid.sbz, by = c("ID1", "Zone"))
# grid.dat.pred <- grid.dat.pred %>% select(ID1, Zone, BGC, everything())
# write.csv(grid.dat, "./outputs/Hexgrid800mPredictedtoSubZone_ranger.csv", row.names = FALSE)
# ```
# # Attribute hexpolygons with subzone predictions 
# ```{r link subzone predictions to hex polygons}
# ###link to hex polygons
# hexZone2 <- left_join(hexZone, grid.sbz, by = "ID1")
# #temp <- select(hexZone, Zone, geometry)
# temp <- hexZone2
# temp$BGC <-  fct_explicit_na(temp$BGC , na_level = "(None)")
# table(temp$BGC)
# 
# temp2 <- temp
# st_precision(temp2) <- 0.5###union polygons within zsubone
# t3 <- temp2 %>%
#   group_by(BGC) %>%
#   summarise(geometry = sf::st_union(geometry)) %>%
#   ungroup()
# 
# mapview(t3)
# t3 <- st_zm(t3, drop=T, what='ZM')
# st_write(t3, dsn = "outputs", layer = "SubzoneRaw800m_ranger_30", driver = "ESRI Shapefile", update = TRUE)


```

## This should probably be done from the spatial file since it will have be simplified with decrumbing

```{r cLHS of trainingpoints for WNA}
#select a subset of training points by BGC from the final surface for full model build
# library(clhs)
# #BGC = "ICHxwz"
# #countZone <- points %>% count(Zone)
# countSubzone <- grid.dat.pred %>% count(BGC)
# 
# rownames(grid.dat.pred) <- grid.dat.pred[,1]
# countSubzone$logn <- log(countSubzone$n, 10)
# countSubzone$rs <- as.integer (rescale(countSubzone$logn, to = c(500, 1200), from = range(countSubzone$logn, na.rm = TRUE, finite = TRUE)))
# countSubzone$sample <- ifelse(countSubzone$rs > countSubzone$n, countSubzone$n, countSubzone$rs )
# write.csv (countSubzone, "./outputs/USA_pts_per_BECLHC2.csv")
# 
# allUnits <- unique(grid.dat.pred$BGC)
# #grid.dat.pred$ID1 <- row.names(grid.dat.pred)
# set.seed(123321)
# coreNo <- makePSOCKcluster(detectCores() - 1)
# registerDoParallel(coreNo, cores = detectCores() - 1)
# Cores <- as.numeric(detectCores()-1)
# 
# BGC = "BGdh_OR"
# LHCtraining <- foreach(BGC = allUnits, .combine = rbind, .packages = c("clhs")) %dopar% {
# temp <- grid.dat.pred[(grid.dat.pred$BGC %in% BGC),]
# temp_names <- temp[1:6]
# Num <- countSubzone$sample[(countSubzone$BGC %in% BGC)]
#   samples <- clhs(temp[,-c(1:6)], 
#                 size = Num,           # Test a range of sample sizes
#                 iter = 10000,        # Arbitrarily large number of iterations of optimization procedure. Default=10,000 but a larger number may be used
#                 progress = TRUE, 
#                 simple = FALSE)
# 
# cLHS <- samples$sampled_data
# cLHS$ID1 <- row.names (cLHS)
# cLHS_Points <- merge (temp[,c(1:5)], cLHS, by = "ID1")
# cLHS_Points
# }
#  stopCluster(coreNo)
#  gc()
# 
# write.csv(LHCtraining, "./outputs/USA_Training_LHC_w_data.csv", row.names = FALSE)
# LHCtraining2 <- LHCtraining [1:3] 
# rownames(grid.dat.raw) <- grid.dat.raw[,1]
# LHCtraining2 <- left_join(LHCtraining2, grid.dat.raw, by = "ID1")
# write.csv(LHCtraining2, "./outputs/USA_LHS_all_dat.csv", row.names = FALSE)
# USA_LHS <- dplyr::select(LHCtraining2, ID1, BGC, Longitude, Latitude, Elevation)
# write.csv(USA_LHS, "./outputs/USA_LHS_for_ClimateNA.csv", row.names = FALSE)
#X1 <- LHCtraining #feed these back into building a new rF model above
```

## orginal sample rebalancing to archive
```{r downsample over sampled units}
# count_tp <- X2  %>% dplyr::count(BGC) %>% filter(n>=2500) %>% select(BGC)
# over_sample <-  as.character(count_tp$BGC)
# 
# #LHCUnits <- c("CWHdm_OR", "IMAun_WY")
# LHCtraining <- foreach(BGC = over_sample, .combine = rbind, .packages = c("clhs", "caret", "dplyr"),.errorhandling="remove") %do% { #
#   temp <- X2[(X2$BGC %in% BGC),]
#   temp <- temp[,-c(2)]
#   temp <- na.omit(temp)
#   temp$xx <- ""
#   temp <- droplevels(temp)
#   Num <- 2500 #X2_LHC$n[(X2_LHC$BGC %in% BGC)]
#   nz <- nearZeroVar(temp, names=T) # remove near zero variance variables which cause cLHS to fail
#    samples <- clhs(temp[, -which (names(temp) %in% nz)], #CMD with all zeros precluded sampling of coastal units
#                   size = Num,           # Test a range of sample sizes
#                   iter = 1000,        # Arbitrarily large number of iterations of optimization procedure. Default=10,000 but a larger number may be used
#                   progress = FALSE, obj.limit = -Inf, eta = 1,use.cpp = T,
#                   simple = FALSE)
# 
#   cLHS <- samples$sampled_data
# 
#   cLHS <-  cLHS %>% select(ID1)#,BGC)
#   #cLHS$ID1 <- row.names(cLHS)
#   cLHS_Points <- left_join (cLHS, X2,  by = "ID1")
#   cLHS_Points
# }
# 
# #LHCtraining <- droplevels(LHCtraining)
# LHCtraining.list <- unique(as.character(LHCtraining$BGC))
# X3 <- X2 %>% filter(!(BGC %in% LHCtraining.list))
# X4 <- rbind(X3, LHCtraining)
# X2 <- X4 %>% drop_na() %>% filter(!BGC == "") %>% droplevels()
countX <- X2 %>% count(BGC)
```

```{r resample training points}
#Calculate sample number and rescale to semi-balance the training point set
# #X2 <- X1#[-1]
# #X2 <- X2 %>% filter(BGC != "MHRFmmp_OR", BGC != "ESSFmwp_WA", BGC != "CMAwh")
# X2$BGC <- as.factor(X2$BGC)
# rownames(X2) <- X2$ID1
# countSubzone <- X2 %>% count(BGC)
# X2_Few <- countSubzone[countSubzone$n <= 250,]## these will need SMOTE additions
# 
# X2_Few$new <- 250
# X2_Few <-  X2_Few %>% mutate(ratio = new/n)
# X2_Few <- droplevels(X2_Few)
# FewUnits <- unique(X2_Few$BGC)

```

 Under trained BGC units are upsampled using the SMOTE to add synthetic points up to the number specified in the resampling.
``` {r add SMOTE units to those BGCs that are undersampled, cache = TRUE}

# X2_Smote <- X2[(X2$BGC %in% X2_Few$BGC),]
# X2_Smote <- X2_Smote %>% mutate_if(is.integer,as.numeric) #select(-Latitude, -Longitude, -Zone)
# X2_Smote$BGC  <- as.factor(X2_Smote$BGC)
# X2_Smote$BGCnum <- as.numeric(X2_Smote$BGC)
# X2_Smote <- droplevels(X2_Smote)
# X2.list <- unique(X2_Smote$BGC)
# countSmote <- X2_Smote %>% count(BGC)
# smote.num <- X2_Few %>% select(BGC, ratio)
# smote.list <- as.character(smote.num$BGC)
# #smote.list$BGC <- as.character(smote.list$BGC)
# #df <- smote.list %>% mutate(name = paste0(BGC, " = ", ratio))
# #BGC = "BGxh1"
# # smote.list <- as.pairlist(df$name)
# #X2_Smote2 <- SmoteClassif(BGC ~ ., X2_Smote, C.perc = list(BGxh1 = 120),  K = 5 )# creates full balanced data set
# # 
# #samples <- smotefamily::SMOTE(X2_Smote[,-c(1:2)], X2_Smote$BGCnum , #CMD with all zeros precluded sampling of coastal units
# #                 K = 2, dup_size = 2) 
# BGC="BGdw_WA"
# # ratio
# X2_Smote2 <- foreach(BGC = smote.list, .combine = rbind, .packages = c("smotefamily", "caret", "dplyr"),.errorhandling="remove") %do% { #
#   temp <- X2_Smote[(X2_Smote$BGC %in% BGC),]
#   temp <- temp[,-c(1)]
#   temp <- na.omit(temp)
#   #temp$xx <- ""
#   temp <- droplevels(temp)
#   Num <- as.numeric(smote.num$ratio[(smote.num$BGC %in% BGC)])
#   #nz <- nearZeroVar(temp, names=T)# remove near zero variance variables which cause cLHS to fail
#   #nz <- nz[nz != "BGCnum"]
# 
#      #smote.exs <- function(data,tgt,N,k)   
#     samples <- smotefamily::SMOTE(temp[-1], temp$BGCnum, #CMD with all zeros precluded sampling of coastal units
#                   K = 5, dup_size = Num)# perc.under = 100, k=5,learner = NULL)           # ratio
                         
# 
#  samples <- SMOTE(BGC ~ ., data = temp[, -which (names(temp) %in% nz)], #CMD with all zeros precluded sampling of coastal units
#                  perc.over = Num, perc.under = 100, k=5,learner = NULL)           # ratio
#                          
  # smote <- samples$data
#   smote$BGC <- BGC
#   smote$ID1 <- row.names(smote)
#   smote_points <- smote %>% dplyr::select(-BGCnum, -class)
#    smote_points <- smote_points %>% dplyr::select(ID1, BGC, everything())
#   smote_points
# }
# count_smote <- X2_Smote2 %>% count(BGC)
# X2_2 <- X2[!X2$BGC %in% smote.list,]
# X2_final <- rbind (X2_2, X2_Smote2 )
# #X2_2 <- rbind (X2_OK2, X2_1)
# 
# # X2_OK3 <- X2[(X2$BGC %in% X2_OK$BGC),]
# # X2_OK3 <- droplevels(X2_OK3)
# 
# # LHC_Final3 <- rbind (LHC_Final2, X2_OK3)
# # LHC_Final3 <- droplevels(LHC_Final3)
# plyr::count(X2_final, vars = "BGC")
# X2_final <- droplevels(X2_final)
# countX <- X2_final %>% count(BGC)
```

3: Set up cross validation

```{r set-up cross validation, eval = TRUE}
## set up cross validation for parameter tuning data sets # note cv best practice is 10 fold x 5 rep
##spatial clustering
  #set.seed(345)
#   BGC_train2$BGC <- as.factor(BGC_train2$BGC)
#   #BGC_cvspatial <- spatial_clustering_cv(BGC_train, 
#   #                       coords = c("Latitude", "Longitude"),
#   #                          v = 5) ### need to build a check for number of tids available to automatically reduce this number where necessary
#                          # repeats = 5, 
#                          # strata = BGC)
# 
#   #summary(BGC_cvspatial)
# ## cv by BGC as strata
# set.seed(345)
# BGC_cvfold <- vfold_cv(BGC_train2, v = 10, repeats = 5, strata = BGC, pool = .02)
# 
# summary(BGC_cvfold)

```
### Run once and use parameters. Only run again when there is significant changes to model inputs
```{r hyper parameter tuning}
# library(tictoc)
#  # look at more bound options (ie c(2, 6, 10))
# ranger_tune_detail <-
#   grid_regular(
#     mtry(range = c(2, 10)),
#     min_n(range = c(2, 10)),
#     levels = 3) #%>% mutate(across(where(is.integer), as.numeric))
# 
# ranger.tst <- rand_forest(mtry = tune(), min_n = tune()) %>%
#   set_mode("classification") %>%
#   set_engine("ranger", importance = "impurity") %>%  translate()#or "permutations
# set.seed(345)
# 
# BGC_cvfold.tst <- vfold_cv(X2, v = 10, repeats = 3, strata = BGC, pool = .02)
# 
# BGC_workflow <- workflow() %>%
#     add_recipe(BGCbalance_recipe) %>%
#     add_model(ranger.tst) 
# # # re-run the tuning with the explicit parameter sets
# 
# tic()
# set.seed(4556)
# doParallel::registerDoParallel()
# ranger_tune <-
#   tune_grid(BGC_workflow,
#             resamples = BGC_cvfold.tst,
#             #metrics = cv_metrics,
#             grid = ranger_tune_detail)
# toc()
# 
# saveRDS(ranger_tune, file = paste(paste0(".", outDir), "parameter_tune_results.rds", sep = "/"))
# 
# # explore ranger tune output
# ranger_tune %>%
#   dplyr::select(.metrics) %>%
#   unnest(cols = c(.metrics))
# 
# # explore results of tuning models note different for type of model selected
# select_best(ranger_tune, metric = "accuracy")
# select_best(ranger_tune, metric = "roc_auc")
# #select_best(ranger_tune, metric = "j_index")
# 
# autoplot(ranger_tune)
```

# Build model of BGCs
The model reduced via RFE to 14 variables is approximately 84.3% accurate and 83% Gini. When all variables are used (44) the accuracy and Gini increase by approximately 1%.
Stay with limited set
**** This  build needs to be replaced with tidymodels version.
**** We'll want to do a formal analysis - training dataset split with control for spatial autocorrelation. 
**** We can apply some of the techniques I had Gen build in for the PEM process re testing point rebalancing to both find optimum downsampling and SMOTE combinations but also identify the BGCs that are not being predicted well.

```{r build ranger model training point size, cache = TRUE, echo=FALSE}

# set.seed(123321)
# coreNo <- makePSOCKcluster(detectCores() - 1)
# registerDoParallel(coreNo, cores = detectCores() - 1)
# Cores <- as.numeric(detectCores()-1)
# ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5,
#                      classProbs = FALSE, verboseIter = T,
#                      savePredictions = "final", 
#                      allowParallel = F)
# 
# 
# #BGCmodel_rang <- train(Zone  ~ ., data = X1_Bio1[-2], #for zone
# BGCmodel_subz <- train(BGC  ~ ., data = X1[,-c(1)], # for subzone
#                      method = "ranger")#,
#                      #preProcess = c("center", "scale", "YeoJohnson"), #,tuneGrid = tgrid,
#                       trControl = ctrl,
#                       importance = "impurity")#, splitrule = "extratrees")
# 
#  stopCluster(coreNo)
#  gc()
# BGCmodel_subz
# # predict the outcome on a test set
# BGC_pred <- predict(BGCmodel_subz , X1[,-c(1:2)])
# # compare predicted outcome and true outcome
# con <- confusionMatrix(BGC_pred, as.factor(X1$BGC)) 
# BGCmodel <- BGCmodel_subz
# file=paste("./outputs/USA_SubZone_RFModel_Mar11",".Rdata",sep="")
# save(BGCmodel,file=file)

# X2 <- X2_final
# X2$BGC <- as.factor(X2$BGC)
# #############simple ranger model
# modelvars <- as.data.frame(colnames(X2[,-c(1:2)]))
# colnames(modelvars) <- "x"
# #X2$BGC <- as.factor(X2$BGC)
# BGCmodel <- ranger(
#   BGC ~ .,
#   data = X2[, -c(1)],
#   #do.trace = 10,
#   num.trees = 501,
#   mtry = 5,
#   min.node.size = 5,
#   importance = "permutation",
#   splitrule = "extratrees",
#   seed = 12345,
#   write.forest = TRUE,
#   classification = TRUE
# )#strata=BGC, sampsize= c(500),, probability = TRUE
# 
# BGCmodel
# save(BGCmodel,file= "./outputs/USAv12_26VAR_SubZone_ranger.Rdata")
# v <-as.data.frame(BGCmodel$variable.importance)
# DF <- v %>% tibble::rownames_to_column() %>% rename(w = rowname, v = 'BGCmodel$variable.importance')
#  
#  ggplot(DF, aes(x=reorder(w,v), y=v,fill=v))+ 
#   geom_bar(stat="identity", position="dodge")+ coord_flip() +
#    ylab("Variable Importance")+
#    xlab("")+
#    ggtitle("Information Value Summary")+
#    guides(fill=F)+
#    scale_fill_gradient(low="red", high="blue")
# 
#  fname <- "USA_12_26var"
# model = "_ranger_7Jan2021"
# write.csv (BGCmodel$variable.importance, file= paste("./outputs/",fname,"_Importance",model,".csv",sep=""))
# write.csv (BGCmodel$prediction.error, file= paste("./outputs/",fname,"_Error",model,".csv",sep=""))
# write.csv (BGCmodel$confusion.matrix, file= paste("./outputs/",fname,"_ConfusionMatrix",model,".csv",sep=""))

####alternate model build
#  fname <- "USA_27var"
# model = "_rf_9Oct2020"
# BGCmodel_rf <- randomForest(as.factor(BGC) ~ ., data = X2[,-c(1)], do.trace = 10,
#                           ntree = 101,   importance = TRUE)#strata=BGC, sampsize= c(500),, probability = TRUE
# 
# confusion.matrix <- as.data.frame(BGCmodel_rf$confusion)
# 
# confusion.matrix <- confusion.matrix %>% rownames_to_column(var = "BGC") %>%  
#     select(BGC, class.error, everything()) %>%
#     mutate (nplot = rowSums(.[,-c(1:2)])) %>% 
#     select(BGC, class.error, nplot, everything())
# write.csv (confusion.matrix , file= paste("./outputs/",fname,"_ConfusionMatrix",model,".csv",sep=""), row.names = FALSE)
# #write.csv (BGCmodel_rf$err.rate, file= paste("./outputs/",fname,"_error",model,".csv",sep=""))
```

```{r test overfit}
# trainIndex <- createDataPartition(X2$BGC, p = .7,
#                                   list = FALSE,
#                                   times = 1)
# 
# 
# BGC_train <- XAll[ trainIndex,]
# BGC_train$BGC <- as.factor(BGC_train$BGC)
# BGC_test  <- XAll[-trainIndex,]# %>% droplevels()
# 
# BGCmodel_train <- ranger(BGC ~ ., data = BGC_train[-1],
#                            num.trees = 501,  seed = 12345,
#                             splitrule =  "extratrees", #""gini",
#                             #always.split.variables = c("DD5","CMD.total", "PPT_JAS"), #,
#                             #split.select.weights = var.weight.vec,
#                     mtry = 5,
#                           #max.depth = .5,
#                     min.node.size = 5,
#                            importance = "permutation", write.forest = TRUE, classification = TRUE)
# 
# BGCmodel_train
# 
#  test.pred <- predict(BGCmodel_train, data = BGC_test[,-c(1)])
#   BGC.pred <- as.data.frame(test.pred$predictions)%>% tibble::rownames_to_column() %>% dplyr::rename("BGC.pred" = "test.pred$predictions")
# 
# BGC.test <- BGC_test %>% select(BGC) %>% cbind(BGC.pred) %>%  select( -rowname) %>% mutate_if(is.character, as.factor)
# levels(BGC.test$BGC.pred) <- levels(BGC.test$BGC)
# BGC_accuracy <- BGC.test %>%                   # test set predictions
#   accuracy(truth = BGC, BGC.pred)
#  table(BGC_accuracy)

```

```{r do cross validation}
#####
# set.seed(123321)
# coreNo <- makePSOCKcluster(detectCores() - 1)
# registerDoParallel(coreNo, cores = detectCores() - 1)
# Cores <- as.numeric(detectCores()-1)
# set.seed(1234)
# tr <- trainControl(method = "cv", number = 3, verboseIter = TRUE)
# tgrid <- expand.grid(
#   .mtry = c(2,3,5),
#   .splitrule = "gini",
#   .min.node.size = c(5, 10, 20)
# )
# 
# tr_cv <- train(BGC ~ .,data=BGC_train[-1],method="ranger", trControl= tr, tuneGrid = tgrid, num.trees = 101, num.threads = 7)
# tr_cv
# tr_cv$bestTune
# stopCluster(coreNo)

```